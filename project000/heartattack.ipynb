{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2437dcc-2b43-42b4-9158-f2c850f01a80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "1    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "2    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "3    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "4    56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "297  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "298  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "299  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "300  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "301  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  num  \n",
       "0      2.0  3.0  3.0    2  \n",
       "1      2.0  2.0  7.0    1  \n",
       "2      3.0  0.0  3.0    0  \n",
       "3      1.0  0.0  3.0    0  \n",
       "4      1.0  0.0  3.0    0  \n",
       "..     ...  ...  ...  ...  \n",
       "297    2.0  0.0  7.0    1  \n",
       "298    2.0  2.0  7.0    2  \n",
       "299    2.0  1.0  7.0    3  \n",
       "300    2.0  1.0  3.0    1  \n",
       "301    1.0    ?  3.0    0  \n",
       "\n",
       "[302 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "read_file1= pd.read_csv (r'C:\\\\Users\\\\revan\\\\Documents\\\\car_data\\processed.cleveland.data')\n",
    "read_file1.to_csv (r'C:\\\\Users\\\\revan\\\\Documents\\\\car_data\\processed.cleveland.csv',index=None)\n",
    "            \n",
    "read_file1.rename(columns={'63.0':'age', '1.0':'sex', '1.0.1':'cp', '145.0':'trestbps', '233.0':'chol', '1.0.2':'fbs', '2.0':'restecg', '150.0':'thalach',\n",
    "       '0.0':'exang', '2.3':'oldpeak', '3.0':'slope', '0.0.1':'ca', '6.0':'thal', '0':'num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f07e3d-f495-4ff2-8b4b-6ccc3dca673d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369949ce-96ef-47ac-b865-cf4cb3c626fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8666666666666667\n",
      "Confusion Matrix:\n",
      "[[32  4]\n",
      " [ 4 20]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        36\n",
      "           1       0.83      0.83      0.83        24\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.86      0.86      0.86        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data['ca'] = data['ca'].astype(float)\n",
    "data['thal'] = data['thal'].astype(float)\n",
    "\n",
    "# Convert target to binary (0 for no disease, 1 for disease)\n",
    "data['target'] = data['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming y2_pred and y2test are your predicted probabilities and true labels respectively\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb9b99d-086f-4375-91a3-e225e4cbb20a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 3.0701134518960362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\revan\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m y_test_regression \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(y_test_clipped \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_test_clipped))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate MSE\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test_regression, y_pred_regression)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error (MSE):\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 101\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Clip y_pred to avoid extreme values\n",
    "y_pred_clipped = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
    "\n",
    "# Apply logit transformation\n",
    "y_pred_regression = np.log(y_pred_clipped / (1 - y_pred_clipped))\n",
    "\n",
    "# Calculate log loss\n",
    "log_loss_value = log_loss(y_test, y_pred_clipped)\n",
    "print(\"Log Loss:\", log_loss_value)\n",
    "\n",
    "# Ensure y_test is in probability form for MSE calculation and clip values\n",
    "y_test_clipped = np.clip(y_test, 1e-10, 1 - 1e-10)\n",
    "\n",
    "# Apply logit transformation to clipped y_test\n",
    "y_test_regression = np.log(y_test_clipped / (1 - y_test_clipped))\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test_regression, y_pred_regression)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ecdce7-a585-42c0-bef4-9beb30d5eacc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Feature Pair: ('age', 'slope')\n",
      "Best Pseudo-Accuracy: 0.9166666666666666\n",
      "Best Mean Squared Error: 0.40684953605792296\n",
      "Best R^2 Score: 0.017667116157932372\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Initialize variables to store the best results\n",
    "best_accuracy = 0\n",
    "best_feature_pair = (None, None)\n",
    "best_mse = None\n",
    "best_r2 = None\n",
    "\n",
    "# Iterate over all possible pairs of features\n",
    "for target_feature in column_names:\n",
    "    if target_feature not in ['ID', 'Diagnosis', 'target']:\n",
    "        for predictor_feature in column_names:\n",
    "            if predictor_feature not in ['ID', 'Diagnosis', 'target', target_feature]:\n",
    "                X = data[[predictor_feature]]\n",
    "                y = data[target_feature]\n",
    "\n",
    "                # Split the data into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Normalize the features\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "                # Initialize and train the linear regression model\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "\n",
    "                # Make predictions on the test set\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "                # Evaluate the model's performance\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                # Convert continuous predictions to binary outcomes using median threshold\n",
    "                median_threshold = np.median(y_train)\n",
    "                y_binary_pred_from_linear = (y_pred > median_threshold).astype(int)\n",
    "                y_binary_test = (y_test > median_threshold).astype(int)\n",
    "\n",
    "                # Calculate pseudo-accuracy for linear regression\n",
    "                pseudo_accuracy = accuracy_score(y_binary_test, y_binary_pred_from_linear)\n",
    "\n",
    "                # Track the best results\n",
    "                if pseudo_accuracy > best_accuracy and pseudo_accuracy < 1:  # Ensure accuracy is less than 1\n",
    "                    best_accuracy = pseudo_accuracy\n",
    "                    best_feature_pair = (predictor_feature, target_feature)\n",
    "                    best_mse = mse\n",
    "                    best_r2 = r2\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best Feature Pair: {best_feature_pair}\")\n",
    "print(f\"Best Pseudo-Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Mean Squared Error: {best_mse}\")\n",
    "print(f\"Best R^2 Score: {best_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee563ee1-b1ff-44b0-85aa-d564f16e6738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Target Feature: restecg\n",
      "Best Pseudo-Accuracy: 0.9166666666666666\n",
      "Best Mean Squared Error: 1.2572131795498231\n",
      "Best R^2 Score: -0.3237693613276871\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data['ca'] = data['ca'].astype(float)\n",
    "data['thal'] = data['thal'].astype(float)\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Initialize variables to store the best results\n",
    "best_accuracy = 0\n",
    "best_target_feature = None\n",
    "best_mse = None\n",
    "best_r2 = None\n",
    "\n",
    "# Iterate over all possible target features\n",
    "for target_feature in column_names:\n",
    "    if target_feature not in ['ID', 'Diagnosis', 'target']:\n",
    "        # Use all other features as predictors\n",
    "        predictor_features = [feature for feature in column_names if feature not in ['ID', 'Diagnosis', 'target', target_feature]]\n",
    "        X = data[predictor_features]\n",
    "        y = data[target_feature]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Define the polynomial regression pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),               # Normalize the features\n",
    "            ('poly', PolynomialFeatures(degree=2)),     # Polynomial feature transformation\n",
    "            ('regressor', LinearRegression())           # Linear regression model\n",
    "        ])\n",
    "\n",
    "        # Train the polynomial regression model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Convert continuous predictions to binary outcomes using median threshold\n",
    "        median_threshold = np.median(y_train)\n",
    "        y_binary_pred_from_linear = (y_pred > median_threshold).astype(int)\n",
    "        y_binary_test = (y_test > median_threshold).astype(int)\n",
    "\n",
    "        # Calculate pseudo-accuracy for polynomial regression\n",
    "        pseudo_accuracy = accuracy_score(y_binary_test, y_binary_pred_from_linear)\n",
    "\n",
    "        # Track the best results\n",
    "        if pseudo_accuracy > best_accuracy and pseudo_accuracy < 1:  # Ensure accuracy is less than 1\n",
    "            best_accuracy = pseudo_accuracy\n",
    "            best_target_feature = target_feature\n",
    "            best_mse = mse\n",
    "            best_r2 = r2\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best Target Feature: {best_target_feature}\")\n",
    "print(f\"Best Pseudo-Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Mean Squared Error: {best_mse}\")\n",
    "print(f\"Best R^2 Score: {best_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45d9569-581e-4f46-8c1b-dcef002595aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2350.673291570983\n",
      "R^2 Score: 0.06417232945770468\n",
      "Value-based Accuracy: 65.00%\n",
      "Percentage-based Accuracy: 63.33%\n",
      "248.0963340159506\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statistics\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data['sex'] = pd.to_numeric(data['sex'])\n",
    "\n",
    "# Selecting only the 'sex' feature for prediction\n",
    "X = data[['age']]\n",
    "y = data['chol']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Define thresholds\n",
    "value_threshold = 50\n",
    "percentage_threshold = 0.20\n",
    "\n",
    "# Calculate value-based accuracy\n",
    "value_accuracy = np.mean(np.abs(y_test - y_pred) <= value_threshold)\n",
    "print(f'Value-based Accuracy: {value_accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate percentage-based accuracy\n",
    "percentage_accuracy = np.mean(np.abs(y_test - y_pred) / y_test <= percentage_threshold)\n",
    "print(f'Percentage-based Accuracy: {percentage_accuracy * 100:.2f}%')\n",
    "print(statistics.mean(y_pred))\n",
    "\n",
    "# # Example prediction\n",
    "# example_sex = 1  # Example: Female (0 for male, 1 for female)\n",
    "# predicted_chol = model.predict([[example_sex]])\n",
    "# print(f'Predicted cholesterol level for sex={example_sex}: {predicted_chol[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ffea45-4fac-4481-9c45-21b839582cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Target Feature: slope\n",
      "Best Pseudo-Accuracy: 0.8833333333333333\n",
      "Best Mean Squared Error: 0.20007316834000116\n",
      "Best R^2 Score: 0.5169259516941622\n"
     ]
    }
   ],
   "source": [
    "#multivariable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data['ca'] = data['ca'].astype(float)\n",
    "data['thal'] = data['thal'].astype(float)\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Initialize variables to store the best results\n",
    "best_accuracy = 0\n",
    "best_target_feature = None\n",
    "best_mse = None\n",
    "best_r2 = None\n",
    "\n",
    "# Iterate over all possible target features\n",
    "for target_feature in column_names:\n",
    "    if target_feature not in ['ID', 'Diagnosis', 'target']:\n",
    "        # Use all other features as predictors\n",
    "        predictor_features = [feature for feature in column_names if feature not in ['ID', 'Diagnosis', 'target', target_feature]]\n",
    "        X = data[predictor_features]\n",
    "        y = data[target_feature]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Define the linear regression pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),               # Normalize the features\n",
    "            ('regressor', LinearRegression())           # Linear regression model\n",
    "        ])\n",
    "\n",
    "        # Train the linear regression model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluate the model's performance\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Convert continuous predictions to binary outcomes using median threshold\n",
    "        median_threshold = np.median(y_train)\n",
    "        y_binary_pred_from_linear = (y_pred > median_threshold).astype(int)\n",
    "        y_binary_test = (y_test > median_threshold).astype(int)\n",
    "\n",
    "        # Calculate pseudo-accuracy for linear regression\n",
    "        pseudo_accuracy = accuracy_score(y_binary_test, y_binary_pred_from_linear)\n",
    "\n",
    "        # Track the best results\n",
    "        if pseudo_accuracy > best_accuracy and pseudo_accuracy < 1:  # Ensure accuracy is less than 1\n",
    "            best_accuracy = pseudo_accuracy\n",
    "            best_target_feature = target_feature\n",
    "            best_mse = mse\n",
    "            best_r2 = r2\n",
    "\n",
    "# Print the best results\n",
    "print(f\"Best Target Feature: {best_target_feature}\")\n",
    "print(f\"Best Pseudo-Accuracy: {best_accuracy}\")\n",
    "print(f\"Best Mean Squared Error: {best_mse}\")\n",
    "print(f\"Best R^2 Score: {best_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be5f5b11-02aa-4dc7-9db8-ec18b32ddca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2704.5630195065396\n",
      "R^2 Score: -0.07671487971352242\n",
      "Value-based Accuracy: 68.33%\n",
      "Percentage-based Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# # Convert relevant columns to numeric\n",
    "# data['ca'] = data['ca'].astype(float)\n",
    "# data['thal'] = data['thal'].astype(float)\n",
    "\n",
    "# Separate features and target variable (predicting 'chol')\n",
    "X = data.drop('chol', axis=1)\n",
    "y = data['chol']\n",
    "\n",
    "# # Identify categorical and numerical columns\n",
    "# categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "# numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# # Preprocessing for categorical data\n",
    "# categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# # Bundle preprocessing for numerical and categorical data\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_cols),\n",
    "#         ('cat', categorical_transformer, categorical_cols)\n",
    "#     ])\n",
    "\n",
    "# # Create and evaluate the model pipeline\n",
    "# model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                         ('regressor', LinearRegression())])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Define thresholds\n",
    "value_threshold = 50\n",
    "percentage_threshold = 0.20\n",
    "\n",
    "# Calculate value-based accuracy\n",
    "value_accuracy = np.mean(np.abs(y_test - y_pred) <= value_threshold)\n",
    "print(f'Value-based Accuracy: {value_accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate percentage-based accuracy\n",
    "percentage_accuracy = np.mean(np.abs(y_test - y_pred) / y_test <= percentage_threshold)\n",
    "print(f'Percentage-based Accuracy: {percentage_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4007587-fe43-4d5c-a126-3331d1e565b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a726ea3-b07f-4e56-a2bf-5cbcb30fadd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.097389925696256e+26\n",
      "R^2 Score: -2.427434825168293e+23\n",
      "Value-based Accuracy: 51.67%\n",
      "Percentage-based Accuracy: 30.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data['ca'] = data['ca'].astype(float)\n",
    "data['thal'] = data['thal'].astype(float)\n",
    "\n",
    "# Separate features and target variable (predicting 'chol')\n",
    "X = data.drop('chol', axis=1)\n",
    "y = data['chol']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the polynomial features transformer\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Create the pipeline with preprocessing and polynomial features\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_features', poly_features),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Define thresholds\n",
    "value_threshold = 70\n",
    "percentage_threshold = 0.20\n",
    "\n",
    "# Calculate value-based accuracy\n",
    "value_accuracy = np.mean(np.abs(y_test - y_pred) <= value_threshold)\n",
    "print(f'Value-based Accuracy: {value_accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate percentage-based accuracy\n",
    "percentage_accuracy = np.mean(np.abs(y_test - y_pred) / y_test <= percentage_threshold)\n",
    "print(f'Percentage-based Accuracy: {percentage_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef40abb6-dfeb-4a16-8af8-1afa1d83a7c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Separate features and target variable (predicting 'chol')\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslope\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Identify categorical and numerical columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', \n",
    "    'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "# Read the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "data = data.replace('?', pd.NA)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert relevant columns to numeric\n",
    "data['ca'] = data['ca'].astype(float)\n",
    "data['thal'] = data['thal'].astype(float)\n",
    "\n",
    "# Separate features and target variable (predicting 'chol')\n",
    "X = data['Age\n",
    "y = data['chol']\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the polynomial features transformer\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Create the pipeline with preprocessing and polynomial features\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly_features', poly_features),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Convert continuous predictions to binary outcomes using median threshold\n",
    "median_threshold = np.median(y_train)\n",
    "y_binary_pred_from_linear = (y_pred > median_threshold).astype(int)\n",
    "y_binary_test = (y_test > median_threshold).astype(int)\n",
    "\n",
    "# Calculate pseudo-accuracy for polynomial regression\n",
    "pseudo_accuracy = accuracy_score(y_binary_test, y_binary_pred_from_linear)\n",
    "\n",
    "print(f'Polynomial Regression Pseudo-Accuracy with Normalization: {pseudo_accuracy}')\n",
    "print(f'Median Threshold: {median_threshold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5323cb8d-98a8-434f-80e2-8176037e70d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ea1cd-eb71-4180-93d6-47c369ea2335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef54912-504d-423b-8ac7-3fa247b8c3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_file1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m read_file1\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m read_file1\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_file1' is not defined"
     ]
    }
   ],
   "source": [
    "x = read_file1.iloc[:,2].values\n",
    "y = read_file1.iloc[:,5].values\n",
    "y\n",
    "         \n",
    "              \n",
    "        \n",
    "            \n",
    "             \n",
    "         \n",
    "            \n",
    "         \n",
    "         \n",
    "              \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b598a79-f45b-4f92-9c5c-ea4623b331fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8544fa16-3740-45d4-8733-621beaca25bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=0)\n",
    "xtrain.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61d66de0-f954-4f13-8852-e6e0f0aa4242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.91658798]\n",
      " [-2.30334285]\n",
      " [ 0.91658798]\n",
      " [ 0.91658798]\n",
      " [-1.23003257]\n",
      " [-0.1567223 ]\n",
      " [-1.23003257]\n",
      " [ 0.91658798]\n",
      " [ 0.91658798]\n",
      " [-1.23003257]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "sc_x = StandardScaler()\n",
    "xtrain = sc_x.fit_transform(xtrain.reshape(-1, 1))\n",
    "xtest = sc_x.transform(xtest.reshape(-1, 1))\n",
    "  \n",
    "print (xtrain[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d6b0c36-057b-421d-9283-6e8d0bf28860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "  \n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d72ddcb3-2866-4971-8fa1-3ec2f100a1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26a1db99-fec5-46aa-a56e-4fe415f11578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[69  0]\n",
      " [ 7  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "  \n",
    "cm = confusion_matrix(ytest, y_pred)\n",
    "print (\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98c83ced-2657-4839-949a-21a40a75fc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "print (\"Accuracy : \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b5567b9-ac0c-40a8-9669-0e369663635b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.regplot(x=x, y=y, data=read_file1, logistic=True, ci=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "420cec35-cfe4-42d4-bccd-2bd67d67be2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4., 160., 286.,   2.],\n",
       "       [  4., 120., 229.,   2.],\n",
       "       [  3., 130., 250.,   0.],\n",
       "       ...,\n",
       "       [  4., 130., 131.,   0.],\n",
       "       [  2., 130., 236.,   2.],\n",
       "       [  3., 138., 175.,   0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = read_file1.iloc[:,[2,3,4,6]].values\n",
    "y1 = read_file1.iloc[:,5].values\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1686f42-88c3-4e90-a1f9-5ab47fe2003f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4., 145., 212.,   2.],\n",
       "       [  1., 150., 240.,   0.],\n",
       "       [  4., 132., 353.,   0.],\n",
       "       [  4., 128., 303.,   2.],\n",
       "       [  2., 132., 288.,   2.],\n",
       "       [  3., 160., 201.,   0.],\n",
       "       [  2., 140., 195.,   0.],\n",
       "       [  4., 132., 207.,   0.],\n",
       "       [  4., 144., 200.,   2.],\n",
       "       [  2., 128., 208.,   2.],\n",
       "       [  4., 115., 303.,   0.],\n",
       "       [  4., 140., 187.,   2.],\n",
       "       [  3., 140., 308.,   2.],\n",
       "       [  4., 112., 149.,   0.],\n",
       "       [  2., 120., 295.,   0.],\n",
       "       [  4., 120., 198.,   0.],\n",
       "       [  3., 128., 229.,   2.],\n",
       "       [  4., 114., 318.,   1.],\n",
       "       [  3., 112., 230.,   2.],\n",
       "       [  2., 140., 221.,   0.],\n",
       "       [  4., 125., 212.,   0.],\n",
       "       [  2., 120., 240.,   0.],\n",
       "       [  4., 125., 300.,   2.],\n",
       "       [  4., 140., 241.,   0.],\n",
       "       [  3., 120., 295.,   2.],\n",
       "       [  4., 124., 266.,   2.],\n",
       "       [  4., 122., 286.,   2.],\n",
       "       [  2., 130., 266.,   0.],\n",
       "       [  4., 128., 259.,   2.],\n",
       "       [  3., 120., 209.,   0.],\n",
       "       [  1., 178., 270.,   2.],\n",
       "       [  4., 110., 172.,   2.],\n",
       "       [  4., 120., 267.,   0.],\n",
       "       [  3., 108., 243.,   0.],\n",
       "       [  4., 110., 201.,   0.],\n",
       "       [  3., 120., 215.,   0.],\n",
       "       [  2., 132., 342.,   0.],\n",
       "       [  3., 112., 268.,   2.],\n",
       "       [  3., 118., 277.,   0.],\n",
       "       [  4., 132., 184.,   2.],\n",
       "       [  3., 130., 233.,   0.],\n",
       "       [  2., 120., 325.,   0.],\n",
       "       [  2., 120., 281.,   2.],\n",
       "       [  1., 120., 231.,   0.],\n",
       "       [  4., 135., 254.,   2.],\n",
       "       [  3., 142., 177.,   2.],\n",
       "       [  2., 101., 197.,   0.],\n",
       "       [  2., 122., 192.,   0.],\n",
       "       [  4., 125., 249.,   2.],\n",
       "       [  2., 120., 284.,   2.],\n",
       "       [  1., 140., 239.,   0.],\n",
       "       [  4., 102., 265.,   2.],\n",
       "       [  4., 140., 239.,   0.],\n",
       "       [  4., 125., 258.,   2.],\n",
       "       [  4., 145., 307.,   2.],\n",
       "       [  4., 124., 274.,   2.],\n",
       "       [  4., 148., 203.,   0.],\n",
       "       [  2., 120., 236.,   0.],\n",
       "       [  4., 150., 258.,   2.],\n",
       "       [  3., 136., 196.,   2.],\n",
       "       [  4., 128., 216.,   2.],\n",
       "       [  4., 170., 326.,   2.],\n",
       "       [  2., 120., 157.,   0.],\n",
       "       [  3., 126., 218.,   0.],\n",
       "       [  4., 174., 249.,   0.],\n",
       "       [  4., 128., 205.,   1.],\n",
       "       [  1., 140., 199.,   0.],\n",
       "       [  3., 129., 196.,   0.],\n",
       "       [  3., 172., 199.,   0.],\n",
       "       [  4., 120., 260.,   0.],\n",
       "       [  4., 180., 325.,   0.],\n",
       "       [  2., 130., 204.,   2.],\n",
       "       [  3., 110., 214.,   0.],\n",
       "       [  4., 200., 288.,   2.],\n",
       "       [  3., 120., 219.,   0.],\n",
       "       [  4., 117., 230.,   0.],\n",
       "       [  2., 130., 245.,   2.],\n",
       "       [  4., 110., 335.,   0.],\n",
       "       [  4., 140., 298.,   0.],\n",
       "       [  1., 110., 211.,   2.],\n",
       "       [  2., 156., 245.,   2.],\n",
       "       [  4., 130., 283.,   2.],\n",
       "       [  3., 130., 180.,   0.],\n",
       "       [  4., 130., 264.,   2.],\n",
       "       [  4., 112., 290.,   2.],\n",
       "       [  3., 130., 250.,   0.],\n",
       "       [  2., 110., 235.,   0.],\n",
       "       [  2., 108., 309.,   0.],\n",
       "       [  3., 120., 226.,   0.],\n",
       "       [  3., 128., 216.,   2.],\n",
       "       [  2., 140., 294.,   2.],\n",
       "       [  2., 118., 210.,   0.],\n",
       "       [  1., 125., 213.,   2.],\n",
       "       [  2., 160., 302.,   0.],\n",
       "       [  3., 150., 168.,   0.],\n",
       "       [  4., 140., 299.,   0.],\n",
       "       [  4., 120., 177.,   0.],\n",
       "       [  2., 105., 204.,   0.],\n",
       "       [  2., 134., 271.,   0.],\n",
       "       [  1., 138., 282.,   2.],\n",
       "       [  3., 108., 267.,   2.],\n",
       "       [  3., 135., 304.,   0.],\n",
       "       [  4., 132., 247.,   2.],\n",
       "       [  4., 180., 327.,   1.],\n",
       "       [  3.,  94., 227.,   0.],\n",
       "       [  4., 112., 230.,   0.],\n",
       "       [  2., 192., 283.,   2.],\n",
       "       [  4., 130., 330.,   2.],\n",
       "       [  2., 135., 203.,   0.],\n",
       "       [  3., 125., 245.,   2.],\n",
       "       [  4., 110., 254.,   2.],\n",
       "       [  4., 123., 282.,   0.],\n",
       "       [  1., 152., 298.,   0.],\n",
       "       [  4., 132., 341.,   2.],\n",
       "       [  1., 110., 264.,   0.],\n",
       "       [  4., 122., 222.,   2.],\n",
       "       [  3.,  94., 199.,   0.],\n",
       "       [  3., 135., 252.,   2.],\n",
       "       [  4., 150., 244.,   0.],\n",
       "       [  4., 100., 248.,   2.],\n",
       "       [  4., 150., 276.,   2.],\n",
       "       [  3., 130., 246.,   2.],\n",
       "       [  3., 130., 263.,   0.],\n",
       "       [  4., 160., 286.,   2.],\n",
       "       [  4., 128., 255.,   0.],\n",
       "       [  4., 124., 197.,   0.],\n",
       "       [  4., 110., 239.,   2.],\n",
       "       [  4., 144., 193.,   0.],\n",
       "       [  4., 138., 166.,   2.],\n",
       "       [  3., 140., 197.,   1.],\n",
       "       [  3., 155., 269.,   0.],\n",
       "       [  2., 105., 198.,   0.],\n",
       "       [  3., 130., 197.,   2.],\n",
       "       [  3., 138., 257.,   2.],\n",
       "       [  4., 130., 131.,   0.],\n",
       "       [  2., 128., 205.,   0.],\n",
       "       [  2., 130., 262.,   0.],\n",
       "       [  4., 130., 206.,   2.],\n",
       "       [  4., 146., 218.,   0.],\n",
       "       [  3., 102., 318.,   0.],\n",
       "       [  3., 105., 240.,   2.],\n",
       "       [  4., 150., 270.,   2.],\n",
       "       [  4., 134., 409.,   2.],\n",
       "       [  1., 118., 182.,   2.],\n",
       "       [  4., 142., 309.,   2.],\n",
       "       [  2., 130., 204.,   2.],\n",
       "       [  4., 140., 207.,   2.],\n",
       "       [  2., 130., 236.,   2.],\n",
       "       [  4., 138., 236.,   2.],\n",
       "       [  4., 120., 354.,   0.],\n",
       "       [  3., 150., 231.,   0.],\n",
       "       [  4., 110., 211.,   0.],\n",
       "       [  3., 140., 235.,   2.],\n",
       "       [  4., 142., 226.,   2.],\n",
       "       [  3., 100., 222.,   0.],\n",
       "       [  1., 170., 288.,   2.],\n",
       "       [  2., 124., 261.,   0.],\n",
       "       [  3., 138., 220.,   0.],\n",
       "       [  3., 125., 309.,   0.],\n",
       "       [  3., 118., 242.,   0.],\n",
       "       [  3., 130., 231.,   0.],\n",
       "       [  3., 180., 274.,   2.],\n",
       "       [  4., 170., 225.,   2.],\n",
       "       [  3., 130., 256.,   2.],\n",
       "       [  4., 130., 256.,   2.],\n",
       "       [  3., 110., 265.,   2.],\n",
       "       [  4., 120., 177.,   2.],\n",
       "       [  3., 125., 273.,   2.],\n",
       "       [  3., 160., 269.,   0.],\n",
       "       [  3., 118., 149.,   2.],\n",
       "       [  3., 140., 185.,   2.],\n",
       "       [  4., 120., 229.,   2.],\n",
       "       [  4., 150., 407.,   2.],\n",
       "       [  4., 152., 223.,   0.],\n",
       "       [  2., 160., 246.,   0.],\n",
       "       [  3., 150., 212.,   0.],\n",
       "       [  4., 140., 177.,   0.],\n",
       "       [  4., 140., 261.,   2.],\n",
       "       [  4., 104., 208.,   2.],\n",
       "       [  3., 130., 275.,   0.],\n",
       "       [  4., 140., 311.,   0.],\n",
       "       [  3., 150., 243.,   0.],\n",
       "       [  4., 130., 253.,   0.],\n",
       "       [  2., 136., 319.,   2.],\n",
       "       [  4., 124., 209.,   0.],\n",
       "       [  4., 110., 167.,   2.],\n",
       "       [  4., 158., 305.,   2.],\n",
       "       [  3., 124., 255.,   0.],\n",
       "       [  3., 115., 564.,   2.],\n",
       "       [  4., 120., 237.,   0.],\n",
       "       [  3., 140., 313.,   0.],\n",
       "       [  3., 140., 335.,   0.],\n",
       "       [  4., 135., 234.,   0.],\n",
       "       [  2., 120., 220.,   0.],\n",
       "       [  3., 120., 240.,   0.],\n",
       "       [  3., 130., 253.,   0.],\n",
       "       [  1., 134., 204.,   0.],\n",
       "       [  2., 128., 308.,   2.],\n",
       "       [  4., 130., 197.,   0.],\n",
       "       [  3., 130., 315.,   0.],\n",
       "       [  4., 115., 260.,   2.],\n",
       "       [  2., 120., 244.,   0.],\n",
       "       [  3., 120., 178.,   0.],\n",
       "       [  3., 140., 211.,   2.],\n",
       "       [  4., 128., 204.,   0.],\n",
       "       [  4., 110., 248.,   2.],\n",
       "       [  3., 120., 340.,   0.],\n",
       "       [  3., 138., 223.,   0.],\n",
       "       [  3., 152., 212.,   2.],\n",
       "       [  4., 152., 274.,   0.],\n",
       "       [  4., 120., 169.,   0.],\n",
       "       [  4., 150., 225.,   2.],\n",
       "       [  3., 120., 211.,   2.],\n",
       "       [  3., 130., 256.,   2.],\n",
       "       [  4., 125., 254.,   0.],\n",
       "       [  4., 138., 234.,   2.],\n",
       "       [  1., 134., 234.,   0.],\n",
       "       [  2., 154., 232.,   2.],\n",
       "       [  3., 130., 214.,   2.],\n",
       "       [  4., 140., 192.,   0.],\n",
       "       [  1., 160., 234.,   2.],\n",
       "       [  4., 128., 263.,   0.],\n",
       "       [  4., 138., 294.,   0.],\n",
       "       [  4., 130., 330.,   2.],\n",
       "       [  3., 140., 417.,   2.],\n",
       "       [  4., 140., 394.,   2.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "x1train, x1test, y1train, y1test = train_test_split(\n",
    "    x1, y1, test_size=0.25, random_state=0)\n",
    "x1train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "352a9f7d-0257-4163-8259-d9a06fb30ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.16587979e-01  7.73186548e-01 -6.88674386e-01  1.06407046e+00]\n",
      " [-2.30334285e+00  1.05936434e+00 -1.64947488e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.91242886e-02  1.94866463e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.99817945e-01  1.01343803e+00  1.06407046e+00]\n",
      " [-1.23003257e+00  2.91242886e-02  7.32870050e-01  1.06407046e+00]\n",
      " [-1.56722297e-01  1.63171992e+00 -8.94424239e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00  4.87008756e-01 -1.00665143e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.91242886e-02 -7.82197046e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  7.15950989e-01 -9.13128771e-01  1.06407046e+00]\n",
      " [-1.23003257e+00 -1.99817945e-01 -7.63492514e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -9.43880204e-01  1.01343803e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  4.87008756e-01 -1.15628769e+00  1.06407046e+00]\n",
      " [-1.56722297e-01  4.87008756e-01  1.10696069e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.11558688e+00 -1.86705991e+00 -9.56769236e-01]\n",
      " [-1.23003257e+00 -6.57702412e-01  8.63801775e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -6.57702412e-01 -9.50537835e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.99817945e-01 -3.70697341e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.00111576e+00  1.29400601e+00  5.36506114e-02]\n",
      " [-1.56722297e-01 -1.11558688e+00 -3.51992809e-01  1.06407046e+00]\n",
      " [-1.23003257e+00  4.87008756e-01 -5.20333598e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -3.71524620e-01 -6.88674386e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -6.57702412e-01 -1.64947488e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -3.71524620e-01  9.57324435e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  4.87008756e-01 -1.46242956e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -6.57702412e-01  8.63801775e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -4.28760179e-01  3.21370345e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -5.43231295e-01  6.95460986e-01  1.06407046e+00]\n",
      " [-1.23003257e+00 -8.53468282e-02  3.21370345e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.99817945e-01  1.90438621e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -6.57702412e-01 -7.44787982e-01 -9.56769236e-01]\n",
      " [-2.30334285e+00  2.66195997e+00  3.96188473e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.23005800e+00 -1.43685567e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -6.57702412e-01  3.40074877e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.34452911e+00 -1.08833892e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.23005800e+00 -8.94424239e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -6.57702412e-01 -6.32560790e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00  2.91242886e-02  1.74291478e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.11558688e+00  3.58779409e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -7.72173529e-01  5.27120198e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.91242886e-02 -1.21240128e+00  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02 -2.95879213e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -6.57702412e-01  1.42493774e+00 -9.56769236e-01]\n",
      " [-1.23003257e+00 -6.57702412e-01  6.01938326e-01  1.06407046e+00]\n",
      " [-2.30334285e+00 -6.57702412e-01 -3.33288277e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.00830964e-01  9.69159604e-02  1.06407046e+00]\n",
      " [-1.56722297e-01  6.01479872e-01 -1.34333301e+00  1.06407046e+00]\n",
      " [-1.23003257e+00 -1.74517802e+00 -9.69242367e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -5.43231295e-01 -1.06276503e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -3.71524620e-01  3.39330006e-03  1.06407046e+00]\n",
      " [-1.23003257e+00 -6.57702412e-01  6.58051922e-01  1.06407046e+00]\n",
      " [-2.30334285e+00  4.87008756e-01 -1.83652021e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.68794246e+00  3.02665813e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  4.87008756e-01 -1.83652021e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -3.71524620e-01  1.71734089e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  7.73186548e-01  1.08825616e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -4.28760179e-01  4.71006602e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  9.44893223e-01 -8.57015175e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -6.57702412e-01 -2.39765617e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  1.05936434e+00  1.71734089e-01  1.06407046e+00]\n",
      " [-1.56722297e-01  2.58066522e-01 -9.87946899e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.99817945e-01 -6.13856258e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  2.20407551e+00  1.44364227e+00  1.06407046e+00]\n",
      " [-1.23003257e+00 -6.57702412e-01 -1.71742365e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01 -3.14289062e-01 -5.76447194e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.43301774e+00  3.39330006e-03 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.99817945e-01 -8.19606110e-01  5.36506114e-02]\n",
      " [-2.30334285e+00  4.87008756e-01 -9.31833303e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.42582387e-01 -9.87946899e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  2.31854662e+00 -9.31833303e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -6.57702412e-01  2.09143153e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.77643109e+00  1.42493774e+00 -9.56769236e-01]\n",
      " [-1.23003257e+00 -8.53468282e-02 -8.38310643e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -1.23005800e+00 -6.51265322e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  3.92114226e+00  7.32870050e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -6.57702412e-01 -5.57742662e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -8.29409087e-01 -3.51992809e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -8.53468282e-02 -7.14248282e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.23005800e+00  1.61198306e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  4.87008756e-01  9.19915371e-01 -9.56769236e-01]\n",
      " [-2.30334285e+00 -1.23005800e+00 -7.07378918e-01  1.06407046e+00]\n",
      " [-1.23003257e+00  1.40277769e+00 -7.14248282e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01 -8.53468282e-02  6.39347390e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02 -1.28721941e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -8.53468282e-02  2.83961281e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.11558688e+00  7.70279114e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02  2.20978321e-02 -9.56769236e-01]\n",
      " [-1.23003257e+00 -1.23005800e+00 -2.58470149e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -1.34452911e+00  1.12566522e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01 -6.57702412e-01 -4.26810937e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.99817945e-01 -6.13856258e-01  1.06407046e+00]\n",
      " [-1.23003257e+00  4.87008756e-01  8.45097243e-01  1.06407046e+00]\n",
      " [-1.23003257e+00 -7.72173529e-01 -7.26083450e-01 -9.56769236e-01]\n",
      " [-2.30334285e+00 -3.71524620e-01 -6.69969854e-01  1.06407046e+00]\n",
      " [-1.23003257e+00  1.63171992e+00  9.94733499e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  1.05936434e+00 -1.51167380e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  4.87008756e-01  9.38619903e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -6.57702412e-01 -1.34333301e+00 -9.56769236e-01]\n",
      " [-1.23003257e+00 -1.51623579e+00 -8.38310643e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00  1.43595405e-01  4.14893005e-01 -9.56769236e-01]\n",
      " [-2.30334285e+00  3.72537639e-01  6.20642858e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -1.34452911e+00  3.40074877e-01  1.06407046e+00]\n",
      " [-1.56722297e-01  2.00830964e-01  1.03214256e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.91242886e-02 -3.40157641e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01  2.77643109e+00  1.46234680e+00  5.36506114e-02]\n",
      " [-1.56722297e-01 -2.14582693e+00 -4.08106405e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.11558688e+00 -3.51992809e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00  3.46325779e+00  6.39347390e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -8.53468282e-02  1.51846040e+00  1.06407046e+00]\n",
      " [-1.23003257e+00  2.00830964e-01 -8.57015175e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -3.71524620e-01 -7.14248282e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.23005800e+00  9.69159604e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01 -4.85995737e-01  6.20642858e-01 -9.56769236e-01]\n",
      " [-2.30334285e+00  1.17383546e+00  9.19915371e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.91242886e-02  1.72421025e+00  1.06407046e+00]\n",
      " [-2.30334285e+00 -1.23005800e+00  2.83961281e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -5.43231295e-01 -5.01629066e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -2.14582693e+00 -9.31833303e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  2.00830964e-01  5.95068962e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.05936434e+00 -9.01293602e-02 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.80241358e+00 -1.53112320e-02  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.05936434e+00  5.08415666e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02 -5.27202961e-02  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02  2.65256749e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  1.63171992e+00  6.95460986e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.99817945e-01  1.15620492e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -4.28760179e-01 -9.69242367e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.23005800e+00 -1.83652021e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  7.15950989e-01 -1.04406050e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  3.72537639e-01 -1.54908286e+00  1.06407046e+00]\n",
      " [-1.56722297e-01  4.87008756e-01 -9.69242367e-01  5.36506114e-02]\n",
      " [-1.56722297e-01  1.34554213e+00  3.77483941e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -1.51623579e+00 -9.50537835e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -8.53468282e-02 -9.69242367e-01  1.06407046e+00]\n",
      " [-1.56722297e-01  3.72537639e-01  1.53029557e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -8.53468282e-02 -2.20374148e+00 -9.56769236e-01]\n",
      " [-1.23003257e+00 -1.99817945e-01 -8.19606110e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -8.53468282e-02  2.46552217e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -8.53468282e-02 -8.00901578e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  8.30422106e-01 -5.76447194e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.68794246e+00  1.29400601e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01 -1.51623579e+00 -1.64947488e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.05936434e+00  3.96188473e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.43595405e-01  2.99611843e+00  1.06407046e+00]\n",
      " [-2.30334285e+00 -7.72173529e-01 -1.24981035e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01  6.01479872e-01  1.12566522e+00  1.06407046e+00]\n",
      " [-1.23003257e+00 -8.53468282e-02 -8.38310643e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  4.87008756e-01 -7.82197046e-01  1.06407046e+00]\n",
      " [-1.23003257e+00 -8.53468282e-02 -2.39765617e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  3.72537639e-01 -2.39765617e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -6.57702412e-01  1.96736917e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01  1.05936434e+00 -3.33288277e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.23005800e+00 -7.07378918e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  4.87008756e-01 -2.58470149e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  6.01479872e-01 -4.26810937e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -1.80241358e+00 -5.01629066e-01 -9.56769236e-01]\n",
      " [-2.30334285e+00  2.20407551e+00  7.32870050e-01  1.06407046e+00]\n",
      " [-1.23003257e+00 -4.28760179e-01  2.27847685e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  3.72537639e-01 -5.39038130e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -3.71524620e-01  1.12566522e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01 -7.72173529e-01 -1.27538424e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -8.53468282e-02 -3.33288277e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  2.77643109e+00  4.71006602e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  2.20407551e+00 -4.45515469e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02  1.34325024e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -8.53468282e-02  1.34325024e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -1.23005800e+00  3.02665813e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -6.57702412e-01 -1.34333301e+00  1.06407046e+00]\n",
      " [-1.56722297e-01 -3.71524620e-01  4.52302069e-01  1.06407046e+00]\n",
      " [-1.56722297e-01  1.63171992e+00  3.77483941e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -7.72173529e-01 -1.86705991e+00  1.06407046e+00]\n",
      " [-1.56722297e-01  4.87008756e-01 -1.19369675e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -6.57702412e-01 -3.70697341e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.05936434e+00  2.95870937e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.17383546e+00 -4.82924533e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00  1.63171992e+00 -5.27202961e-02 -9.56769236e-01]\n",
      " [-1.56722297e-01  1.05936434e+00 -6.88674386e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  4.87008756e-01 -1.34333301e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  4.87008756e-01  2.27847685e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.57347135e+00 -7.63492514e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02  4.89711134e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  4.87008756e-01  1.16307429e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01  1.05936434e+00 -1.08833892e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -8.53468282e-02  7.82114283e-02 -9.56769236e-01]\n",
      " [-1.23003257e+00  2.58066522e-01  1.31271054e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -4.28760179e-01 -7.44787982e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.23005800e+00 -1.53037833e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.51724881e+00  1.05084710e+00  1.06407046e+00]\n",
      " [-1.56722297e-01 -4.28760179e-01  1.15620492e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -9.43880204e-01  5.89532090e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -6.57702412e-01 -2.21061085e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  4.87008756e-01  1.20048335e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01  4.87008756e-01  1.61198306e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  2.00830964e-01 -2.77174681e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -6.57702412e-01 -5.39038130e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -6.57702412e-01 -1.64947488e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -8.53468282e-02  7.82114283e-02 -9.56769236e-01]\n",
      " [-2.30334285e+00  1.43595405e-01 -8.38310643e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00 -1.99817945e-01  1.10696069e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01 -8.53468282e-02 -9.69242367e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01 -8.53468282e-02  1.23789242e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -9.43880204e-01  2.09143153e-01  1.06407046e+00]\n",
      " [-1.23003257e+00 -6.57702412e-01 -9.01293602e-02 -9.56769236e-01]\n",
      " [-1.56722297e-01 -6.57702412e-01 -1.32462848e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01  4.87008756e-01 -7.07378918e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.99817945e-01 -8.38310643e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -1.23005800e+00 -1.53112320e-02  1.06407046e+00]\n",
      " [-1.56722297e-01 -6.57702412e-01  1.70550572e+00 -9.56769236e-01]\n",
      " [-1.56722297e-01  3.72537639e-01 -4.82924533e-01 -9.56769236e-01]\n",
      " [-1.56722297e-01  1.17383546e+00 -6.88674386e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  1.17383546e+00  4.71006602e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -6.57702412e-01 -1.49296926e+00 -9.56769236e-01]\n",
      " [ 9.16587979e-01  1.05936434e+00 -4.45515469e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -6.57702412e-01 -7.07378918e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02  1.34325024e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -3.71524620e-01  9.69159604e-02 -9.56769236e-01]\n",
      " [ 9.16587979e-01  3.72537639e-01 -2.77174681e-01  1.06407046e+00]\n",
      " [-2.30334285e+00  1.43595405e-01 -2.77174681e-01 -9.56769236e-01]\n",
      " [-1.23003257e+00  1.28830657e+00 -3.14583745e-01  1.06407046e+00]\n",
      " [-1.56722297e-01 -8.53468282e-02 -6.51265322e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01  4.87008756e-01 -1.06276503e+00 -9.56769236e-01]\n",
      " [-2.30334285e+00  1.63171992e+00 -2.77174681e-01  1.06407046e+00]\n",
      " [ 9.16587979e-01 -1.99817945e-01  2.65256749e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01  3.72537639e-01  8.45097243e-01 -9.56769236e-01]\n",
      " [ 9.16587979e-01 -8.53468282e-02  1.51846040e+00  1.06407046e+00]\n",
      " [-1.56722297e-01  4.87008756e-01  3.14575469e+00  1.06407046e+00]\n",
      " [ 9.16587979e-01  4.87008756e-01  2.71555045e+00  1.06407046e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "sc_x = StandardScaler()\n",
    "x1train = sc_x.fit_transform(x1train)\n",
    "x1test = sc_x.transform(x1test)\n",
    "  \n",
    "print (x1train)\n",
    "    #feature Scaling  \n",
    "# from sklearn.preprocessing import StandardScaler    \n",
    "#     st_x= StandardScaler()    \n",
    "#     x1train= st_x.fit_transform(x1train)    \n",
    "#     x1test= st_x.transform(x1test)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07c51ab6-90ef-4e01-b1d8-2e5e98d8374c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "  \n",
    "# classifier = LogisticRegression(random_state = 0)\n",
    "# classifier.fit(x1train, y1train)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "  \n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(x1train, y1train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9a97f1a-0900-4af9-a2a0-5ca1a65c37ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y1_pred = classifier.predict(x1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47ac3ffb-6914-443d-95ea-d5004646805c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[69  0]\n",
      " [ 7  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "  \n",
    "cm = confusion_matrix(y1test, y1_pred)\n",
    "print (\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0305e3ee-75aa-44a3-b565-c3d45d56e018",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "print (\"Accuracy : \", accuracy_score(y1test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed572bf2-f42f-4bb0-90c0-f8ba3e237a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "1    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "2    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "3    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "4    56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "297  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "298  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "299  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "300  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "301  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  num  \n",
       "0      2.0  3.0  3.0    2  \n",
       "1      2.0  2.0  7.0    1  \n",
       "2      3.0  0.0  3.0    0  \n",
       "3      1.0  0.0  3.0    0  \n",
       "4      1.0  0.0  3.0    0  \n",
       "..     ...  ...  ...  ...  \n",
       "297    2.0  0.0  7.0    1  \n",
       "298    2.0  2.0  7.0    2  \n",
       "299    2.0  1.0  7.0    3  \n",
       "300    2.0  1.0  3.0    1  \n",
       "301    1.0    ?  3.0    0  \n",
       "\n",
       "[302 rows x 14 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file1.rename(columns={'63.0':'age', '1.0':'sex', '1.0.1':'cp', '145.0':'trestbps', '233.0':'chol', '1.0.2':'fbs', '2.0':'restecg', '150.0':'thalach',\n",
    "       '0.0':'exang', '2.3':'oldpeak', '3.0':'slope', '0.0.1':'ca', '6.0':'thal', '0':'num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bac4d69-de3b-4ba4-9590-72ab587cc547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = read_file1.iloc[:,3].values\n",
    "y = read_file1.iloc[:,5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8dcdbcc-3554-4d3b-b916-3940f652750b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1204967699301096"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Reshape X to a column vector\n",
    "X = x.reshape(-1, 1)\n",
    "\n",
    "# Degree of polynomial\n",
    "degree = 2\n",
    "\n",
    "# Transform the features to include polynomial terms up to the specified degree\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Initialize and fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "## Calculate the mean squared error\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc08083e-6c35-4a18-a490-fc365d93bef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acurracy= 1-mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a1c4182-ac2b-4282-a550-f7a0ec21adbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8795032300698904"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc16a58d-1c65-45b4-b08c-e6430dd93560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "1    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "2    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "3    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "4    56.0  1.0  2.0     120.0  236.0  0.0      0.0    178.0    0.0      0.8   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "297  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "298  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "299  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "300  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "301  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  num  \n",
       "0      2.0  3.0  3.0    2  \n",
       "1      2.0  2.0  7.0    1  \n",
       "2      3.0  0.0  3.0    0  \n",
       "3      1.0  0.0  3.0    0  \n",
       "4      1.0  0.0  3.0    0  \n",
       "..     ...  ...  ...  ...  \n",
       "297    2.0  0.0  7.0    1  \n",
       "298    2.0  2.0  7.0    2  \n",
       "299    2.0  1.0  7.0    3  \n",
       "300    2.0  1.0  3.0    1  \n",
       "301    1.0    ?  3.0    0  \n",
       "\n",
       "[302 rows x 14 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file1.rename(columns={'63.0':'age', '1.0':'sex', '1.0.1':'cp', '145.0':'trestbps', '233.0':'chol', '1.0.2':'fbs', '2.0':'restecg', '150.0':'thalach',\n",
    "       '0.0':'exang', '2.3':'oldpeak', '3.0':'slope', '0.0.1':'ca', '6.0':'thal', '0':'num'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64136abf-ba4e-43aa-ba0f-a184d7d3b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4afd2df3-9de8-4688-a06f-5415816cf615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Sample data\n",
    "X4 = read_file1.iloc[:,3].values\n",
    "y4 = read_file1.iloc[:,5].values\n",
    "\n",
    "# Reshape X to a column vector\n",
    "X = X4.reshape(-1, 1)\n",
    "\n",
    "# Initialize and fit a simple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y4)\n",
    "\n",
    "# Predict\n",
    "y4_pred = model.predict(X)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "#simple linear regression\n",
    "mse = mean_squared_error(y4, y4_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6643a47-c288-4eef-a0fb-af365a4ace5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) for Logistic Regression: 0.081270720787972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate some sample data\n",
    "X =read_file1.iloc[:,[3]].values\n",
    "y = read_file1.iloc[:,5].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train.reshape(-1,1), y_train)\n",
    "\n",
    "# Make probability predictions on the test data\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for probability predictions\n",
    "mse = mean_squared_error(y_test, y_prob)\n",
    "print(f\"Mean Squared Error (MSE) for Logistic Regression: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb00a8b-fd42-4c19-b7f9-9c20acd082e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.08176222814261475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate some sample data\n",
    "X = read_file1.iloc[:,[2,3]].values\n",
    "y = read_file1.iloc[:,5].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "y_prob = logistic_regression.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_prob)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9521895-1bfd-4cc9-b58c-0573c7ccd88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: 0.9180327868852459\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "x = read_file1.iloc[:,3].values\n",
    "y = read_file1.iloc[:,5].values\n",
    "X = x.reshape(-1, 1)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Polynomial feature transformation\n",
    "degree = 2\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Create and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Define a threshold for classification\n",
    "threshold = 0.5  # Adjust as needed\n",
    "\n",
    "# Convert continuous predictions to binary labels\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy as a measure of classification performance\n",
    "accuracy = np.mean(y_pred_binary == y_test)\n",
    "print(f\"Classification Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b9d73c-a608-4973-b815-fd75378ecd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-like Metric: 0.92\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "X =read_file1.iloc[:,3].values\n",
    "y = read_file1.iloc[:,5].values\n",
    "\n",
    "X = x.reshape(-1, 1)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make continuous predictions on the test data\n",
    "y_pred_continuous = model.predict(X_test)\n",
    "\n",
    "# Define a tolerance level for rounding predictions\n",
    "tolerance = 0.5  # Adjust as needed\n",
    "\n",
    "# Round predictions to the nearest integer\n",
    "y_pred_rounded = np.round(y_pred_continuous)\n",
    "\n",
    "# Calculate the percentage of predictions within the tolerance\n",
    "accuracy_like_metric = np.mean(np.abs(y_test - y_pred_rounded) <= tolerance) \n",
    "\n",
    "print(f\"Accuracy-like Metric: {accuracy_like_metric:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb33787-a133-4818-b3fc-476631cd4ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
